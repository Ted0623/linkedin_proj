{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linkedin Job Listing Scrapper\n",
    "This script will scrape through the job listings on Linkedin for data analyst roles in Canada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute chrome drivers and set the default zoom to 40% so all listings can be shown (this avoids having to scroll)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=webdriver.Chrome(\"chromedriver.exe\")\n",
    "wd.get('chrome://settings/')\n",
    "wd.execute_script('chrome.settingsPrivate.setDefaultZoom(0.4);')\n",
    "wd.get(\"https://www.google.ca/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These chunks will open Linkedin and send the username and password keys to the Linkedin site for login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user=\"email\"\n",
    "userpass=\"password\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd.get(\"https://www.linkedin.com\")\n",
    "username=wd.find_element_by_id(\"session_key\")\n",
    "username.send_keys(user)\n",
    "password=wd.find_element_by_id(\"session_password\")\n",
    "password.send_keys(userpass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_button=wd.find_element_by_class_name(\"sign-in-form__submit-button\")\n",
    "login_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the position and loc variables if you want to search for a different job title in a different location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position='data analyst'\n",
    "loc='canada'\n",
    "position = position.replace(' ', \"%20\")\n",
    "wd.get(f\"https://www.linkedin.com/jobs/search/?currentJobId=3087504630&geoId=101174742&keywords={position}&location={loc}&refresh=true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell retrieves the total number of jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_jobs = wd.find_element_by_css_selector('small.display-flex.t-12.t-black--light.t-normal').text\n",
    "no_of_jobs=int(no_of_jobs.split(' ')[0].replace(',',''))\n",
    "print(no_of_jobs)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bread and butter of the script, this cell will begin to retrieve the data from the listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_list = []\n",
    "\n",
    "for i in range(1, 30):\n",
    "    # this loop is to click to the next page and retrieve the total number of jobs in a page\n",
    "    wd.find_element_by_xpath(f'//button[@aria-label=\"Page {i}\"]').click() # click to the next page\n",
    "    jobs_lists = wd.find_element_by_class_name(\"jobs-search-results-list\")  \n",
    "    jobs = jobs_lists.find_elements_by_class_name('jobs-search-results__list-item')  \n",
    "    for j in range(1, len(jobs)+1):\n",
    "        # this loop clicks through each listing and retrieves the necessary elements\n",
    "        # click on each job listing\n",
    "        wd.find_element_by_xpath(f\"/html/body/div[5]/div[3]/div[4]/div/div/main/div/section[1]/div/ul/li[{j}]/div/div[1]/div[1]/div[2]/div[1]/a\").click()\n",
    "        time.sleep(1)\n",
    "        # get the job description from the right panel\n",
    "        job_desc = wd.find_element_by_class_name('jobs-description-content__text.t-14.t-normal')\n",
    "        soup = BeautifulSoup(job_desc.get_attribute('outerHTML'), 'html.parser')\n",
    "        des=soup.text.strip()\n",
    "        # get the top cards to extract elements like title, company name, etc.\n",
    "        cards = wd.find_element_by_class_name('jobs-unified-top-card.t-14')\n",
    "        title = cards.find_element_by_class_name('t-24.t-bold').text.strip() # job title\n",
    "        try:\n",
    "            company = cards.find_element_by_class_name('ember-view.t-black.t-normal').text.strip() # company name\n",
    "        except NoSuchElementException:\n",
    "            company=cards.find_element_by_class_name('jobs-unified-top-card__company-name')\n",
    "        location = cards.find_element_by_class_name('jobs-unified-top-card__bullet').text.strip() # location of the job\n",
    "        try:\n",
    "            placetype = cards.find_element_by_class_name('jobs-unified-top-card__workplace-type').text.strip() #workplace type\n",
    "        except NoSuchElementException:\n",
    "            placetype = ''\n",
    "        postdate = cards.find_element_by_class_name('jobs-unified-top-card__posted-date').text #how long ago the job was posted\n",
    "        # add the elements to a list\n",
    "        record=(title, company, location, placetype, postdate, des)\n",
    "        desc_list.append(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will create the data frame and remove any unnecessary words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(desc_list)\n",
    "\n",
    "# deleting useless words\n",
    "df = df.replace(['\\n',\n",
    "                 '^.*?Expect',\n",
    "                 '^.*?Qualifications',\n",
    "                 '^.*?Required',\n",
    "                 '^.*?expected',\n",
    "                 '^.*?Responsibilities',\n",
    "                 '^.*?Requirements',\n",
    " ], '', regex=True)\n",
    "df.rename(columns={0:'job_title', 1:'company_name', 2:'location', 3:'workplace_type', 4:'job_posted', 5:'job_desc'}, inplace=True)\n",
    "df.to_csv('linkedin_jobs.csv')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e8901ad9e28f1de3770652873e5de76a25bd2fe8436a3bfc64bcd9233978153"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
